# 结果输出与导出

<cite>
**Referenced Files in This Document **  
- [src/database.py](file://src/database.py)
- [src/exporter.py](file://src/exporter.py)
- [src/logger_config.py](file://src/logger_config.py)
</cite>

## 目录
1. [数据库管理](#数据库管理)
2. [Excel导出处理](#excel导出处理)
3. [日志系统集成](#日志系统集成)

## 数据库管理

`DatabaseManager` 类负责搜索结果的持久化存储，通过SQLite实现高效的数据管理。该组件在初始化时自动创建数据库文件、表结构及索引，确保后续操作的性能和数据完整性。

### 初始化流程
当 `DatabaseManager` 实例化时，会立即调用 `init_database()` 方法完成以下初始化步骤：
1. 确保数据库文件所在目录存在（若路径包含子目录则自动创建）
2. 建立与SQLite数据库的连接
3. 创建名为 `search_results` 的主表，包含文件路径、行号、匹配内容和搜索关键词等字段
4. 在 `file_path` 字段上创建索引以加速基于文件路径的查询操作
5. 提交事务并关闭连接

此过程保证了每次运行都能在一个一致且优化的状态下开始数据存储。

### 批量插入机制
为提高写入效率，系统采用批量插入策略。`save_results()` 方法将所有匹配结果收集到一个列表中，然后使用 `executemany()` 一次性执行多条INSERT语句。这种方式显著减少了I/O开销和事务处理时间，特别适合处理大量搜索结果的情况。

```mermaid
classDiagram
class DatabaseManager {
+str db_path
+__init__(db_path : str)
+init_database()
+save_results(file_results : List[Dict])
+get_results() -> List[str]
}
DatabaseManager --> "sqlite3" : 使用
```

**Diagram sources **  
- [src/database.py](file://src/database.py#L7-L98)

**Section sources**  
- [src/database.py](file://src/database.py#L7-L98)

## Excel导出处理

`ExcelExporter` 类提供强大的Excel导出功能，能够智能地处理大规模数据集，并自动应对各种潜在问题。

### DataFrame转换与特殊字符清理
在导出前，系统首先将原始结果转换为pandas DataFrame格式。在此过程中，`_clean_excel_content()` 方法会对每个字符串字段进行清理：
- 移除Excel禁止使用的特殊字符：`\ / ? * [ ] :`
- 过滤ASCII控制字符（除制表符、换行符和回车符外的所有0-31范围字符）
- 将超过32,767个字符的单元格内容截断并在末尾添加省略号，避免超出Excel单元格长度限制

这些措施确保生成的Excel文件不会因格式错误而损坏或无法打开。

### 自动分片导出机制
当匹配结果超过预设阈值时，系统会自动启动分片导出模式。核心参数 `max_rows_per_file` 默认设置为100,000行，这是为了防止单个Excel文件过大导致性能下降或内存溢出。

分片逻辑如下：
1. 计算所需文件数量：`(总行数 + 每文件最大行数 - 1) // 每文件最大行数`
2. 对于每个分片，提取相应范围的数据块
3. 应用相同的字符清理规则
4. 使用命名约定 `_part_n.xlsx` 生成独立文件（如 `results_part_1.xlsx`, `results_part_2.xlsx`）

用户可通过构造函数自定义 `max_rows_per_file` 参数来调整分片策略，例如：

```python
exporter = ExcelExporter("output.xlsx", max_rows_per_file=50000)
```

这使得系统既适用于小型项目也支持企业级大规模代码库分析。

```mermaid
classDiagram
class ExcelExporter {
+str excel_path
+int max_rows_per_file
+__init__(excel_path : str, max_rows_per_file : int)
+export_to_excel(file_results : List[Dict])
-_export_to_single_excel(data : List[Dict], ...)
-_export_to_multiple_excel(data : List[Dict], ...)
-_create_and_export_dataframe(data : List[Dict], path : str)
-_clean_excel_content(content : str) -> str
}
ExcelExporter --> "pandas" : 使用
ExcelExporter --> "openpyxl" : 使用
```

**Diagram sources **  
- [src/exporter.py](file://src/exporter.py#L15-L149)

**Section sources**  
- [src/exporter.py](file://src/exporter.py#L15-L149)

## 日志系统集成

整个结果处理流程与统一的日志系统深度集成，便于监控和故障排查。`logger_config.py` 配置了Loguru作为日志框架，具备以下特性：

- 文件日志：按日期滚动保存至 `logs/` 目录，每日一个文件，保留最近10天记录
- 控制台输出：实时显示关键信息，便于调试
- 格式化：包含时间戳、日志级别、源文件位置和详细消息
- 编码：使用UTF-8编码，正确处理中文字符

所有数据库操作和导出动作都会生成相应的INFO级别日志，包括初始化状态、保存统计、拆分决策和最终完成提示。错误情况则记录ERROR级别日志并抛出异常，确保问题不会被忽略。

**Section sources**  
- [src/logger_config.py](file://src/logger_config.py#L1-L24)